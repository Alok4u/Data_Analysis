# -*- coding: utf-8 -*-
"""Data analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ase2WFnNrecpDF1NZtEaGGUfzE6CEM69
"""

#importing libraries
import pandas as pd
import nltk
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Define path
dataset_path = "/content/customer_support_tickets.csv"

# Load the dataset
df = pd.read_csv(dataset_path)

# Display the first few rows
print(df.head())

# Check the columns
print(df.columns)

# Get basic statistics about the dataset
print(df.describe())

# Check the shape of the dataset
print(df.shape)

"""#Data Preprocessing ,Data Quality & Handling missing data"""

df.dropna(inplace=True)  # Remove rows with missing values

# Check for duplicates
duplicates = df[df.duplicated()]
if not duplicates.empty:
    print("Found duplicates, removing them.")
    df.drop_duplicates(inplace=True)

# Data Cleaning and Text Normalization
text_columns = ['Customer Name', 'Customer Email', 'Ticket Subject', 'Ticket Description']
df[text_columns] = df[text_columns].apply(lambda x: x.str.lower())

# Exploring and Understanding the Data
# Summary statistics
print(df.describe())

# Distribution of data
print(df['Customer Satisfaction Rating'].value_counts())

# Categorical Data Handling (Example: One-Hot Encoding for 'Ticket Type')
df = pd.get_dummies(df, columns=['Ticket Type'])


# Visualize data for numerical columns
import matplotlib.pyplot as plt
plt.boxplot(df['Customer Age'])
plt.show()

"""# Text Preprocessing and NLP"""

# Lowercase and remove punctuation
df['Ticket Subject'] = df['Ticket Subject'].str.lower()
df['Ticket Description'] = df['Ticket Description'].str.lower()
df['Ticket Subject'] = df['Ticket Subject'].str.replace('[^\w\s]', '')
df['Ticket Description'] = df['Ticket Description'].str.replace('[^\w\s]', '')

# Tokenization and stopwords removal
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))
df['Ticket Subject'] = df['Ticket Subject'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))
df['Ticket Description'] = df['Ticket Description'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))

# TF-IDF Vectorization
tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed
subject_tfidf = tfidf_vectorizer.fit_transform(df['Ticket Subject'])
description_tfidf = tfidf_vectorizer.fit_transform(df['Ticket Description'])

# Now you have TF-IDF representations of the text data in subject_tfidf and description_tfidf

"""#Text classification"""

# Split the dataset into training and testing sets
X = df['Ticket Description']
y = df['Ticket Priority']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# TF-IDF Vectorization
tfidf_vectorizer = TfidfVectorizer(max_features=5000)
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

# Train a simple logistic regression model
clf = LogisticRegression()
clf.fit(X_train_tfidf, y_train)

# Make predictions
y_pred = clf.predict(X_test_tfidf)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
print(classification_report(y_test, y_pred))

"""#data visualization"""

# Create a bar chart for 'Ticket Priority'
priority_counts = df['Ticket Priority'].value_counts()
priority_counts.plot(kind='bar')
plt.title('Ticket Priority Distribution')
plt.xlabel('Priority')
plt.ylabel('Count')
plt.show()

# Create a histogram for 'Customer Age'
plt.hist(df['Customer Age'], bins=20)
plt.title('Customer Age Distribution')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.show()

# Create a scatter plot between 'Customer Age' and 'Customer Satisfaction Rating'
plt.scatter(df['Customer Age'], df['Customer Satisfaction Rating'])
plt.title('Customer Age vs. Satisfaction Rating')
plt.xlabel('Age')
plt.ylabel('Satisfaction Rating')
plt.show()

"""#statistical analysis"""

import scipy.stats as stats

# Sample data for t-test
sample_data1 = [1, 2, 3, 4, 5]
sample_data2 = [6, 7, 8, 9, 10]

# Perform a t-test
t_stat, p_value = stats.ttest_ind(sample_data1, sample_data2)

print("T-statistic:", t_stat)
print("P-value:", p_value)

# Assuming 'X' contains your text data and 'y' contains the target labels

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# TF-IDF Vectorization
tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

# Train a logistic regression model
model = LogisticRegression()
model.fit(X_train_tfidf, y_train)

# Make predictions
y_pred = model.predict(X_test_tfidf)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
print(classification_report(y_test, y_pred))

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Assuming 'df' is your DataFrame with 'Ticket Description' and 'Ticket Priority' columns

# Text preprocessing
# Lowercase text and remove punctuation
df['Ticket Description'] = df['Ticket Description'].str.lower()
df['Ticket Description'] = df['Ticket Description'].str.replace('[^\w\s]', '')

# Split the data
X = df['Ticket Description']
y = df['Ticket Priority']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# TF-IDF Vectorization
tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

# Train a logistic regression model
model = LogisticRegression()
model.fit(X_train_tfidf, y_train)

# Make predictions
y_pred = model.predict(X_test_tfidf)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
print(classification_report(y_test, y_pred))

df.to_excel('output.xlsx', index=False)

"""#saving & loading the model"""

import joblib

# Assuming 'model' is your trained machine learning model
joblib.dump(model, 'your_model.pkl')

# Load the model
loaded_model = joblib.load('your_model.pkl')

import joblib
from sklearn.feature_extraction.text import TfidfVectorizer

# Define and fit the TF-IDF vectorizer on your training data
tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)  # Assuming X_train is your training text data

# Save the TF-IDF vectorizer to a file
joblib.dump(tfidf_vectorizer, 'your_tfidf_vectorizer.pkl')

"""#deployement of pre-train model on new dataset"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Load the dataset (replace '/content/sample.csv' with your dataset path)
dataset_path = '/content/sample.csv'
df = pd.read_csv(dataset_path)

# Data preprocessing
df['text'] = df['text'].str.lower()  # Convert text to lowercase
df['text'] = df['text'].str.replace('[^\w\s]', '')  # Remove punctuation

# Split the data
X = df['text']
y = df['inbound']  # Replace 'your_target_column_name' with 'inbound'

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# TF-IDF Vectorization
tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Adjust max_features as needed
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

# Train a logistic regression model
model = LogisticRegression()
model.fit(X_train_tfidf, y_train)

# Make predictions
y_pred = model.predict(X_test_tfidf)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
print(classification_report(y_test, y_pred))

import joblib
from sklearn.feature_extraction.text import TfidfVectorizer

# Load the pre-trained model
loaded_model = joblib.load('your_model.pkl')

# Define your new data (text data in this example)
new_data = [
    "This is a new tweet.",
    "Another example tweet for prediction."
    # Add more new data as needed
]

# Load the same TF-IDF vectorizer used during model training
tfidf_vectorizer = joblib.load('your_tfidf_vectorizer.pkl')

# Convert the new data into TF-IDF features
new_data_tfidf = tfidf_vectorizer.transform(new_data)

# Make predictions on the new data
predictions = loaded_model.predict(new_data_tfidf)

# Print the predictions
for text, prediction in zip(new_data, predictions):
    print(f"Text: {text}")
    if prediction == 1:
        print("Predicted Class: Inbound")
    else:
        print("Predicted Class: Outbound")
    print()